{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Grayscale\n",
    "\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "\troot='data',\n",
    "\ttrain=True,\n",
    "\ttransform=transforms.Compose([\n",
    "\t\tToTensor(),\n",
    "\t\t# Grayscale(1),\n",
    "\t\t# transforms.Normalize((0.1307,), (0.3081,)),\n",
    "\t]),\n",
    "\tdownload=True,\n",
    ");\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "\ttrain_data,\n",
    "\tbatch_size=BATCH,\n",
    "\tnum_workers=12,\n",
    "\tshuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data in trainloader:\n",
    "\tprint(data[0].shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(G, self).__init__()\n",
    "\n",
    "\t\tself.deconvs = nn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(1, 24, 3),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.ConvTranspose2d(24, 32, 3),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.ConvTranspose2d(32, 40, 3),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.ConvTranspose2d(40, 1, 3),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.deconvs(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise shape: torch.Size([4, 1, 20, 20])\n",
      "out shape: torch.Size([4, 1, 28, 28])\n",
      "out 0 shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16b54ffd0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = G()\n",
    "\n",
    "noise = torch.randn(BATCH, 1, 20, 20)\n",
    "print('noise shape:', noise.shape)\n",
    "\n",
    "out = generator(noise)\n",
    "\n",
    "print('out shape:', out.shape)\n",
    "print('out 0 shape:', out[0].shape)\n",
    "\n",
    "imshow(out[0].reshape(28, 28).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(D, self).__init__()\n",
    "\n",
    "\t\tself.convs = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(1, 16, 3),\n",
    "\t\t\tnn.BatchNorm2d(16),\n",
    "\t\t\tnn.LeakyReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(16, 32, 3),\n",
    "\t\t\tnn.BatchNorm2d(32),\n",
    "\t\t\tnn.LeakyReLU(inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(32, 64, 3),\n",
    "\t\t\tnn.BatchNorm2d(64),\n",
    "\t\t\tnn.Sigmoid(),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.classifier = nn.Linear(64 * 22 * 22, 1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.convs(x)\n",
    "\n",
    "\t\tx = x.reshape(x.shape[0], -1)\n",
    "\n",
    "\t\tx = self.classifier(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = G()\n",
    "discriminator = D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "g_optim = optim.Adam(generator.parameters(), lr=3e-4)\n",
    "d_optim = optim.Adam(discriminator.parameters(), lr=3e-4)\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0.2142],\n",
      "        [0.0845],\n",
      "        [0.2612],\n",
      "        [0.2021]], grad_fn=<AddmmBackward>)\n",
      "1\n",
      "tensor([[0.1020],\n",
      "        [0.1996],\n",
      "        [0.1577],\n",
      "        [0.1574]], grad_fn=<AddmmBackward>)\n",
      "2\n",
      "tensor([[0.2652],\n",
      "        [0.1760],\n",
      "        [0.2269],\n",
      "        [0.2325]], grad_fn=<AddmmBackward>)\n",
      "3\n",
      "tensor([[0.1710],\n",
      "        [0.0695],\n",
      "        [0.1688],\n",
      "        [0.1620]], grad_fn=<AddmmBackward>)\n",
      "4\n",
      "tensor([[0.2351],\n",
      "        [0.0327],\n",
      "        [0.2368],\n",
      "        [0.2542]], grad_fn=<AddmmBackward>)\n",
      "5\n",
      "tensor([[0.1322],\n",
      "        [0.2222],\n",
      "        [0.1055],\n",
      "        [0.2237]], grad_fn=<AddmmBackward>)\n",
      "6\n",
      "tensor([[0.2058],\n",
      "        [0.2150],\n",
      "        [0.3129],\n",
      "        [0.2393]], grad_fn=<AddmmBackward>)\n",
      "7\n",
      "tensor([[0.2997],\n",
      "        [0.2428],\n",
      "        [0.3779],\n",
      "        [0.1630]], grad_fn=<AddmmBackward>)\n",
      "8\n",
      "tensor([[ 0.1800],\n",
      "        [ 0.1710],\n",
      "        [-0.0276],\n",
      "        [ 0.3002]], grad_fn=<AddmmBackward>)\n",
      "9\n",
      "tensor([[0.2198],\n",
      "        [0.1733],\n",
      "        [0.2897],\n",
      "        [0.2324]], grad_fn=<AddmmBackward>)\n",
      "10\n",
      "tensor([[0.2174],\n",
      "        [0.1106],\n",
      "        [0.2071],\n",
      "        [0.0227]], grad_fn=<AddmmBackward>)\n",
      "11\n",
      "tensor([[0.0549],\n",
      "        [0.1751],\n",
      "        [0.0901],\n",
      "        [0.1580]], grad_fn=<AddmmBackward>)\n",
      "12\n",
      "tensor([[0.1404],\n",
      "        [0.1507],\n",
      "        [0.2317],\n",
      "        [0.1306]], grad_fn=<AddmmBackward>)\n",
      "13\n",
      "tensor([[0.0949],\n",
      "        [0.2404],\n",
      "        [0.0945],\n",
      "        [0.1683]], grad_fn=<AddmmBackward>)\n",
      "14\n",
      "tensor([[0.0140],\n",
      "        [0.1094],\n",
      "        [0.2567],\n",
      "        [0.0021]], grad_fn=<AddmmBackward>)\n",
      "15\n",
      "tensor([[0.1192],\n",
      "        [0.1877],\n",
      "        [0.1286],\n",
      "        [0.1513]], grad_fn=<AddmmBackward>)\n",
      "16\n",
      "tensor([[0.2483],\n",
      "        [0.2262],\n",
      "        [0.1675],\n",
      "        [0.1727]], grad_fn=<AddmmBackward>)\n",
      "17\n",
      "tensor([[0.1093],\n",
      "        [0.1727],\n",
      "        [0.2614],\n",
      "        [0.1602]], grad_fn=<AddmmBackward>)\n",
      "18\n",
      "tensor([[0.1343],\n",
      "        [0.1983],\n",
      "        [0.0381],\n",
      "        [0.0225]], grad_fn=<AddmmBackward>)\n",
      "19\n",
      "tensor([[0.2163],\n",
      "        [0.2371],\n",
      "        [0.0387],\n",
      "        [0.1938]], grad_fn=<AddmmBackward>)\n",
      "20\n",
      "tensor([[0.3269],\n",
      "        [0.1509],\n",
      "        [0.1484],\n",
      "        [0.0895]], grad_fn=<AddmmBackward>)\n",
      "21\n",
      "tensor([[0.0853],\n",
      "        [0.1484],\n",
      "        [0.1840],\n",
      "        [0.1314]], grad_fn=<AddmmBackward>)\n",
      "22\n",
      "tensor([[0.1213],\n",
      "        [0.0274],\n",
      "        [0.1056],\n",
      "        [0.2631]], grad_fn=<AddmmBackward>)\n",
      "23\n",
      "tensor([[0.1175],\n",
      "        [0.1044],\n",
      "        [0.1357],\n",
      "        [0.1055]], grad_fn=<AddmmBackward>)\n",
      "24\n",
      "tensor([[0.1572],\n",
      "        [0.1421],\n",
      "        [0.1136],\n",
      "        [0.1586]], grad_fn=<AddmmBackward>)\n",
      "25\n",
      "tensor([[0.1355],\n",
      "        [0.3387],\n",
      "        [0.1644],\n",
      "        [0.1319]], grad_fn=<AddmmBackward>)\n",
      "26\n",
      "tensor([[0.1209],\n",
      "        [0.0600],\n",
      "        [0.1921],\n",
      "        [0.0603]], grad_fn=<AddmmBackward>)\n",
      "27\n",
      "tensor([[0.2033],\n",
      "        [0.1512],\n",
      "        [0.2932],\n",
      "        [0.0405]], grad_fn=<AddmmBackward>)\n",
      "28\n",
      "tensor([[0.0048],\n",
      "        [0.0916],\n",
      "        [0.0921],\n",
      "        [0.1694]], grad_fn=<AddmmBackward>)\n",
      "29\n",
      "tensor([[0.1406],\n",
      "        [0.1306],\n",
      "        [0.1394],\n",
      "        [0.1548]], grad_fn=<AddmmBackward>)\n",
      "30\n",
      "tensor([[0.1880],\n",
      "        [0.0360],\n",
      "        [0.1674],\n",
      "        [0.1525]], grad_fn=<AddmmBackward>)\n",
      "31\n",
      "tensor([[0.1234],\n",
      "        [0.2313],\n",
      "        [0.1576],\n",
      "        [0.2069]], grad_fn=<AddmmBackward>)\n",
      "32\n",
      "tensor([[0.1653],\n",
      "        [0.0498],\n",
      "        [0.0772],\n",
      "        [0.1702]], grad_fn=<AddmmBackward>)\n",
      "33\n",
      "tensor([[0.1356],\n",
      "        [0.0971],\n",
      "        [0.1053],\n",
      "        [0.0745]], grad_fn=<AddmmBackward>)\n",
      "34\n",
      "tensor([[0.0928],\n",
      "        [0.1462],\n",
      "        [0.0676],\n",
      "        [0.2068]], grad_fn=<AddmmBackward>)\n",
      "35\n",
      "tensor([[ 0.1762],\n",
      "        [ 0.1144],\n",
      "        [ 0.1721],\n",
      "        [-0.0118]], grad_fn=<AddmmBackward>)\n",
      "36\n",
      "tensor([[-0.0045],\n",
      "        [ 0.1842],\n",
      "        [ 0.2100],\n",
      "        [ 0.2332]], grad_fn=<AddmmBackward>)\n",
      "37\n",
      "tensor([[0.0936],\n",
      "        [0.0054],\n",
      "        [0.2001],\n",
      "        [0.1795]], grad_fn=<AddmmBackward>)\n",
      "38\n",
      "tensor([[0.2235],\n",
      "        [0.1321],\n",
      "        [0.1695],\n",
      "        [0.2115]], grad_fn=<AddmmBackward>)\n",
      "39\n",
      "tensor([[0.1353],\n",
      "        [0.1526],\n",
      "        [0.2030],\n",
      "        [0.0806]], grad_fn=<AddmmBackward>)\n",
      "40\n",
      "tensor([[0.0794],\n",
      "        [0.0261],\n",
      "        [0.1500],\n",
      "        [0.0872]], grad_fn=<AddmmBackward>)\n",
      "41\n",
      "tensor([[0.1657],\n",
      "        [0.1924],\n",
      "        [0.0921],\n",
      "        [0.1297]], grad_fn=<AddmmBackward>)\n",
      "42\n",
      "tensor([[0.0871],\n",
      "        [0.2704],\n",
      "        [0.2073],\n",
      "        [0.0160]], grad_fn=<AddmmBackward>)\n",
      "43\n",
      "tensor([[0.0245],\n",
      "        [0.0729],\n",
      "        [0.0830],\n",
      "        [0.0973]], grad_fn=<AddmmBackward>)\n",
      "44\n",
      "tensor([[0.1695],\n",
      "        [0.0358],\n",
      "        [0.0870],\n",
      "        [0.0102]], grad_fn=<AddmmBackward>)\n",
      "45\n",
      "tensor([[0.0969],\n",
      "        [0.1821],\n",
      "        [0.0481],\n",
      "        [0.0820]], grad_fn=<AddmmBackward>)\n",
      "46\n",
      "tensor([[0.0796],\n",
      "        [0.0977],\n",
      "        [0.1670],\n",
      "        [0.1142]], grad_fn=<AddmmBackward>)\n",
      "47\n",
      "tensor([[0.1453],\n",
      "        [0.0591],\n",
      "        [0.1474],\n",
      "        [0.0660]], grad_fn=<AddmmBackward>)\n",
      "48\n",
      "tensor([[0.1911],\n",
      "        [0.0631],\n",
      "        [0.0434],\n",
      "        [0.1414]], grad_fn=<AddmmBackward>)\n",
      "49\n",
      "tensor([[ 0.1902],\n",
      "        [ 0.0909],\n",
      "        [ 0.1457],\n",
      "        [-0.0727]], grad_fn=<AddmmBackward>)\n",
      "50\n",
      "tensor([[0.1261],\n",
      "        [0.1099],\n",
      "        [0.0837],\n",
      "        [0.1635]], grad_fn=<AddmmBackward>)\n",
      "51\n",
      "tensor([[0.0851],\n",
      "        [0.1946],\n",
      "        [0.0527],\n",
      "        [0.1377]], grad_fn=<AddmmBackward>)\n",
      "52\n",
      "tensor([[ 0.1158],\n",
      "        [ 0.0681],\n",
      "        [-0.0523],\n",
      "        [ 0.1146]], grad_fn=<AddmmBackward>)\n",
      "53\n",
      "tensor([[0.1867],\n",
      "        [0.0127],\n",
      "        [0.0532],\n",
      "        [0.0282]], grad_fn=<AddmmBackward>)\n",
      "54\n",
      "tensor([[0.0941],\n",
      "        [0.1516],\n",
      "        [0.2278],\n",
      "        [0.0294]], grad_fn=<AddmmBackward>)\n",
      "55\n",
      "tensor([[0.0662],\n",
      "        [0.1559],\n",
      "        [0.0650],\n",
      "        [0.0630]], grad_fn=<AddmmBackward>)\n",
      "56\n",
      "tensor([[ 0.0607],\n",
      "        [ 0.0198],\n",
      "        [ 0.2624],\n",
      "        [-0.0065]], grad_fn=<AddmmBackward>)\n",
      "57\n",
      "tensor([[ 0.1182],\n",
      "        [-0.0072],\n",
      "        [ 0.1517],\n",
      "        [ 0.1332]], grad_fn=<AddmmBackward>)\n",
      "58\n",
      "tensor([[0.1305],\n",
      "        [0.0285],\n",
      "        [0.0786],\n",
      "        [0.0868]], grad_fn=<AddmmBackward>)\n",
      "59\n",
      "tensor([[ 0.0025],\n",
      "        [-0.0692],\n",
      "        [ 0.1134],\n",
      "        [ 0.0005]], grad_fn=<AddmmBackward>)\n",
      "60\n",
      "tensor([[0.1228],\n",
      "        [0.1847],\n",
      "        [0.0833],\n",
      "        [0.0917]], grad_fn=<AddmmBackward>)\n",
      "61\n",
      "tensor([[-0.0420],\n",
      "        [ 0.0185],\n",
      "        [ 0.1266],\n",
      "        [ 0.1131]], grad_fn=<AddmmBackward>)\n",
      "62\n",
      "tensor([[-0.0043],\n",
      "        [ 0.1345],\n",
      "        [-0.0375],\n",
      "        [ 0.1701]], grad_fn=<AddmmBackward>)\n",
      "63\n",
      "tensor([[ 0.1519],\n",
      "        [-0.0948],\n",
      "        [ 0.0446],\n",
      "        [ 0.0736]], grad_fn=<AddmmBackward>)\n",
      "64\n",
      "tensor([[ 0.0386],\n",
      "        [-0.0591],\n",
      "        [ 0.1359],\n",
      "        [ 0.0717]], grad_fn=<AddmmBackward>)\n",
      "65\n",
      "tensor([[0.0253],\n",
      "        [0.0513],\n",
      "        [0.0705],\n",
      "        [0.0496]], grad_fn=<AddmmBackward>)\n",
      "66\n",
      "tensor([[0.0729],\n",
      "        [0.1315],\n",
      "        [0.1176],\n",
      "        [0.1680]], grad_fn=<AddmmBackward>)\n",
      "67\n",
      "tensor([[0.0257],\n",
      "        [0.1033],\n",
      "        [0.1480],\n",
      "        [0.1022]], grad_fn=<AddmmBackward>)\n",
      "68\n",
      "tensor([[-0.0068],\n",
      "        [ 0.1039],\n",
      "        [ 0.1072],\n",
      "        [ 0.0529]], grad_fn=<AddmmBackward>)\n",
      "69\n",
      "tensor([[0.1152],\n",
      "        [0.0209],\n",
      "        [0.1242],\n",
      "        [0.0814]], grad_fn=<AddmmBackward>)\n",
      "70\n",
      "tensor([[ 0.0116],\n",
      "        [ 0.1516],\n",
      "        [-0.0175],\n",
      "        [ 0.0215]], grad_fn=<AddmmBackward>)\n",
      "71\n",
      "tensor([[0.1698],\n",
      "        [0.0553],\n",
      "        [0.1336],\n",
      "        [0.1033]], grad_fn=<AddmmBackward>)\n",
      "72\n",
      "tensor([[ 0.1136],\n",
      "        [-0.0191],\n",
      "        [ 0.1533],\n",
      "        [ 0.1510]], grad_fn=<AddmmBackward>)\n",
      "73\n",
      "tensor([[-0.0061],\n",
      "        [ 0.0833],\n",
      "        [ 0.1031],\n",
      "        [ 0.0840]], grad_fn=<AddmmBackward>)\n",
      "74\n",
      "tensor([[ 0.0855],\n",
      "        [-0.0770],\n",
      "        [ 0.0755],\n",
      "        [-0.0258]], grad_fn=<AddmmBackward>)\n",
      "75\n",
      "tensor([[-0.0560],\n",
      "        [-0.0303],\n",
      "        [ 0.0874],\n",
      "        [ 0.0980]], grad_fn=<AddmmBackward>)\n",
      "76\n",
      "tensor([[0.0824],\n",
      "        [0.0212],\n",
      "        [0.1455],\n",
      "        [0.0137]], grad_fn=<AddmmBackward>)\n",
      "77\n",
      "tensor([[0.1115],\n",
      "        [0.1531],\n",
      "        [0.0893],\n",
      "        [0.0555]], grad_fn=<AddmmBackward>)\n",
      "78\n",
      "tensor([[0.0889],\n",
      "        [0.0350],\n",
      "        [0.0080],\n",
      "        [0.0325]], grad_fn=<AddmmBackward>)\n",
      "79\n",
      "tensor([[-0.0450],\n",
      "        [ 0.0029],\n",
      "        [ 0.0260],\n",
      "        [ 0.0695]], grad_fn=<AddmmBackward>)\n",
      "80\n",
      "tensor([[-0.0064],\n",
      "        [ 0.0521],\n",
      "        [ 0.0647],\n",
      "        [-0.0733]], grad_fn=<AddmmBackward>)\n",
      "81\n",
      "tensor([[-0.0266],\n",
      "        [-0.0031],\n",
      "        [ 0.1093],\n",
      "        [ 0.0664]], grad_fn=<AddmmBackward>)\n",
      "82\n",
      "tensor([[0.1140],\n",
      "        [0.0713],\n",
      "        [0.0545],\n",
      "        [0.0978]], grad_fn=<AddmmBackward>)\n",
      "83\n",
      "tensor([[-0.0434],\n",
      "        [ 0.0978],\n",
      "        [ 0.0583],\n",
      "        [ 0.0246]], grad_fn=<AddmmBackward>)\n",
      "84\n",
      "tensor([[-0.0007],\n",
      "        [ 0.0578],\n",
      "        [ 0.0704],\n",
      "        [ 0.0452]], grad_fn=<AddmmBackward>)\n",
      "85\n",
      "tensor([[ 0.1201],\n",
      "        [-0.0537],\n",
      "        [ 0.0764],\n",
      "        [ 0.0457]], grad_fn=<AddmmBackward>)\n",
      "86\n",
      "tensor([[0.0352],\n",
      "        [0.0120],\n",
      "        [0.0702],\n",
      "        [0.1245]], grad_fn=<AddmmBackward>)\n",
      "87\n",
      "tensor([[-0.0123],\n",
      "        [ 0.0292],\n",
      "        [ 0.1223],\n",
      "        [-0.0617]], grad_fn=<AddmmBackward>)\n",
      "88\n",
      "tensor([[ 0.1247],\n",
      "        [-0.0949],\n",
      "        [-0.0264],\n",
      "        [ 0.0531]], grad_fn=<AddmmBackward>)\n",
      "89\n",
      "tensor([[0.1529],\n",
      "        [0.0384],\n",
      "        [0.0975],\n",
      "        [0.0298]], grad_fn=<AddmmBackward>)\n",
      "90\n",
      "tensor([[ 0.0731],\n",
      "        [ 0.0898],\n",
      "        [-0.0013],\n",
      "        [ 0.0095]], grad_fn=<AddmmBackward>)\n",
      "91\n",
      "tensor([[ 0.0967],\n",
      "        [-0.0292],\n",
      "        [ 0.1236],\n",
      "        [ 0.0631]], grad_fn=<AddmmBackward>)\n",
      "92\n",
      "tensor([[-0.0186],\n",
      "        [ 0.0441],\n",
      "        [-0.0756],\n",
      "        [-0.0029]], grad_fn=<AddmmBackward>)\n",
      "93\n",
      "tensor([[0.0516],\n",
      "        [0.0352],\n",
      "        [0.0419],\n",
      "        [0.0566]], grad_fn=<AddmmBackward>)\n",
      "94\n",
      "tensor([[-0.0686],\n",
      "        [ 0.0613],\n",
      "        [ 0.0305],\n",
      "        [-0.0106]], grad_fn=<AddmmBackward>)\n",
      "95\n",
      "tensor([[ 0.1112],\n",
      "        [ 0.0719],\n",
      "        [-0.0176],\n",
      "        [ 0.0374]], grad_fn=<AddmmBackward>)\n",
      "96\n",
      "tensor([[ 0.0775],\n",
      "        [ 0.1011],\n",
      "        [-0.0430],\n",
      "        [ 0.0662]], grad_fn=<AddmmBackward>)\n",
      "97\n",
      "tensor([[ 0.1646],\n",
      "        [ 0.0503],\n",
      "        [-0.1145],\n",
      "        [ 0.0406]], grad_fn=<AddmmBackward>)\n",
      "98\n",
      "tensor([[-4.9582e-02],\n",
      "        [ 1.1145e-01],\n",
      "        [ 2.6475e-02],\n",
      "        [ 9.7757e-05]], grad_fn=<AddmmBackward>)\n",
      "99\n",
      "tensor([[ 0.0248],\n",
      "        [-0.0035],\n",
      "        [-0.0475],\n",
      "        [-0.0136]], grad_fn=<AddmmBackward>)\n",
      "100\n",
      "tensor([[ 0.0375],\n",
      "        [-0.0223],\n",
      "        [ 0.0691],\n",
      "        [ 0.0078]], grad_fn=<AddmmBackward>)\n",
      "101\n",
      "tensor([[ 0.0484],\n",
      "        [-0.0040],\n",
      "        [ 0.0508],\n",
      "        [ 0.0526]], grad_fn=<AddmmBackward>)\n",
      "102\n",
      "tensor([[-0.0816],\n",
      "        [ 0.0094],\n",
      "        [ 0.0348],\n",
      "        [ 0.0534]], grad_fn=<AddmmBackward>)\n",
      "103\n",
      "tensor([[-0.0386],\n",
      "        [-0.0781],\n",
      "        [ 0.1040],\n",
      "        [-0.0179]], grad_fn=<AddmmBackward>)\n",
      "104\n",
      "tensor([[ 0.0625],\n",
      "        [-0.0044],\n",
      "        [-0.0685],\n",
      "        [ 0.0576]], grad_fn=<AddmmBackward>)\n",
      "105\n",
      "tensor([[-0.1090],\n",
      "        [-0.0834],\n",
      "        [ 0.0741],\n",
      "        [-0.0214]], grad_fn=<AddmmBackward>)\n",
      "106\n",
      "tensor([[-0.0795],\n",
      "        [-0.0704],\n",
      "        [ 0.0433],\n",
      "        [-0.0697]], grad_fn=<AddmmBackward>)\n",
      "107\n",
      "tensor([[0.0293],\n",
      "        [0.0301],\n",
      "        [0.0656],\n",
      "        [0.0057]], grad_fn=<AddmmBackward>)\n",
      "108\n",
      "tensor([[ 0.0525],\n",
      "        [-0.0432],\n",
      "        [ 0.0535],\n",
      "        [ 0.0649]], grad_fn=<AddmmBackward>)\n",
      "109\n",
      "tensor([[ 0.1068],\n",
      "        [ 0.0481],\n",
      "        [-0.0083],\n",
      "        [ 0.0359]], grad_fn=<AddmmBackward>)\n",
      "110\n",
      "tensor([[ 0.0155],\n",
      "        [-0.0542],\n",
      "        [-0.0962],\n",
      "        [ 0.0748]], grad_fn=<AddmmBackward>)\n",
      "111\n",
      "tensor([[-0.1025],\n",
      "        [-0.0581],\n",
      "        [ 0.0789],\n",
      "        [-0.0110]], grad_fn=<AddmmBackward>)\n",
      "112\n",
      "tensor([[-0.0116],\n",
      "        [ 0.0130],\n",
      "        [-0.0192],\n",
      "        [ 0.0053]], grad_fn=<AddmmBackward>)\n",
      "113\n",
      "tensor([[-0.0016],\n",
      "        [ 0.0766],\n",
      "        [ 0.0105],\n",
      "        [ 0.0752]], grad_fn=<AddmmBackward>)\n",
      "114\n",
      "tensor([[ 0.0257],\n",
      "        [ 0.0104],\n",
      "        [-0.0137],\n",
      "        [ 0.0471]], grad_fn=<AddmmBackward>)\n",
      "115\n",
      "tensor([[-0.0747],\n",
      "        [-0.0348],\n",
      "        [-0.0627],\n",
      "        [-0.0438]], grad_fn=<AddmmBackward>)\n",
      "116\n",
      "tensor([[-4.5670e-05],\n",
      "        [-1.1265e-01],\n",
      "        [ 6.7201e-02],\n",
      "        [ 5.2375e-03]], grad_fn=<AddmmBackward>)\n",
      "117\n",
      "tensor([[ 0.0193],\n",
      "        [ 0.1360],\n",
      "        [-0.0374],\n",
      "        [-0.0543]], grad_fn=<AddmmBackward>)\n",
      "118\n",
      "tensor([[-0.0945],\n",
      "        [-0.0403],\n",
      "        [-0.1743],\n",
      "        [-0.0712]], grad_fn=<AddmmBackward>)\n",
      "119\n",
      "tensor([[-0.0684],\n",
      "        [-0.0517],\n",
      "        [-0.0254],\n",
      "        [-0.0169]], grad_fn=<AddmmBackward>)\n",
      "120\n",
      "tensor([[-0.0232],\n",
      "        [ 0.0779],\n",
      "        [-0.0815],\n",
      "        [-0.0072]], grad_fn=<AddmmBackward>)\n",
      "121\n",
      "tensor([[-0.0283],\n",
      "        [-0.0219],\n",
      "        [ 0.0503],\n",
      "        [-0.0028]], grad_fn=<AddmmBackward>)\n",
      "122\n",
      "tensor([[-9.4891e-02],\n",
      "        [ 4.8897e-02],\n",
      "        [ 3.4459e-07],\n",
      "        [-1.2118e-02]], grad_fn=<AddmmBackward>)\n",
      "123\n",
      "tensor([[-0.0809],\n",
      "        [-0.0299],\n",
      "        [-0.1324],\n",
      "        [-0.0112]], grad_fn=<AddmmBackward>)\n",
      "124\n",
      "tensor([[-0.0517],\n",
      "        [ 0.0029],\n",
      "        [ 0.0078],\n",
      "        [ 0.0006]], grad_fn=<AddmmBackward>)\n",
      "125\n",
      "tensor([[-0.1521],\n",
      "        [-0.0358],\n",
      "        [-0.0080],\n",
      "        [-0.0463]], grad_fn=<AddmmBackward>)\n",
      "126\n",
      "tensor([[-0.0105],\n",
      "        [ 0.0896],\n",
      "        [ 0.0108],\n",
      "        [-0.0856]], grad_fn=<AddmmBackward>)\n",
      "127\n",
      "tensor([[ 0.0496],\n",
      "        [-0.0285],\n",
      "        [-0.0312],\n",
      "        [-0.0368]], grad_fn=<AddmmBackward>)\n",
      "128\n",
      "tensor([[-0.1132],\n",
      "        [-0.0210],\n",
      "        [-0.0537],\n",
      "        [-0.0717]], grad_fn=<AddmmBackward>)\n",
      "129\n",
      "tensor([[ 0.0241],\n",
      "        [-0.1150],\n",
      "        [ 0.0988],\n",
      "        [-0.0595]], grad_fn=<AddmmBackward>)\n",
      "130\n",
      "tensor([[ 0.0012],\n",
      "        [-0.0425],\n",
      "        [-0.1431],\n",
      "        [-0.0969]], grad_fn=<AddmmBackward>)\n",
      "131\n",
      "tensor([[-0.0024],\n",
      "        [ 0.0460],\n",
      "        [-0.0976],\n",
      "        [-0.0116]], grad_fn=<AddmmBackward>)\n",
      "132\n",
      "tensor([[-0.0123],\n",
      "        [-0.1233],\n",
      "        [ 0.0122],\n",
      "        [-0.0367]], grad_fn=<AddmmBackward>)\n",
      "133\n",
      "tensor([[-0.0642],\n",
      "        [-0.0734],\n",
      "        [-0.1047],\n",
      "        [-0.0371]], grad_fn=<AddmmBackward>)\n",
      "134\n",
      "tensor([[-0.0320],\n",
      "        [ 0.0207],\n",
      "        [-0.0584],\n",
      "        [-0.1191]], grad_fn=<AddmmBackward>)\n",
      "135\n",
      "tensor([[-0.0562],\n",
      "        [-0.1374],\n",
      "        [-0.0113],\n",
      "        [-0.0171]], grad_fn=<AddmmBackward>)\n",
      "136\n",
      "tensor([[-0.0681],\n",
      "        [-0.1075],\n",
      "        [-0.0221],\n",
      "        [-0.0551]], grad_fn=<AddmmBackward>)\n",
      "137\n",
      "tensor([[-0.0178],\n",
      "        [-0.0779],\n",
      "        [-0.0029],\n",
      "        [-0.0950]], grad_fn=<AddmmBackward>)\n",
      "138\n",
      "tensor([[-0.0686],\n",
      "        [-0.0109],\n",
      "        [-0.0954],\n",
      "        [-0.0362]], grad_fn=<AddmmBackward>)\n",
      "139\n",
      "tensor([[-0.0309],\n",
      "        [ 0.0599],\n",
      "        [-0.0644],\n",
      "        [-0.0853]], grad_fn=<AddmmBackward>)\n",
      "140\n",
      "tensor([[-0.0748],\n",
      "        [ 0.0156],\n",
      "        [ 0.0064],\n",
      "        [-0.0044]], grad_fn=<AddmmBackward>)\n",
      "141\n",
      "tensor([[-0.0557],\n",
      "        [-0.0107],\n",
      "        [-0.0506],\n",
      "        [-0.0148]], grad_fn=<AddmmBackward>)\n",
      "142\n",
      "tensor([[-0.0302],\n",
      "        [-0.1114],\n",
      "        [ 0.0018],\n",
      "        [ 0.0140]], grad_fn=<AddmmBackward>)\n",
      "143\n",
      "tensor([[-0.0511],\n",
      "        [-0.0822],\n",
      "        [-0.0428],\n",
      "        [-0.1049]], grad_fn=<AddmmBackward>)\n",
      "144\n",
      "tensor([[-0.1044],\n",
      "        [-0.1358],\n",
      "        [-0.1271],\n",
      "        [-0.0102]], grad_fn=<AddmmBackward>)\n",
      "145\n",
      "tensor([[-0.0719],\n",
      "        [-0.0676],\n",
      "        [-0.0529],\n",
      "        [-0.1155]], grad_fn=<AddmmBackward>)\n",
      "146\n",
      "tensor([[ 0.0005],\n",
      "        [-0.1152],\n",
      "        [-0.1395],\n",
      "        [-0.0884]], grad_fn=<AddmmBackward>)\n",
      "147\n",
      "tensor([[-0.0719],\n",
      "        [ 0.0084],\n",
      "        [ 0.0147],\n",
      "        [-0.0161]], grad_fn=<AddmmBackward>)\n",
      "148\n",
      "tensor([[-0.0406],\n",
      "        [-0.1431],\n",
      "        [-0.0404],\n",
      "        [-0.0778]], grad_fn=<AddmmBackward>)\n",
      "149\n",
      "tensor([[-0.0319],\n",
      "        [-0.0449],\n",
      "        [-0.0448],\n",
      "        [-0.0767]], grad_fn=<AddmmBackward>)\n",
      "150\n",
      "tensor([[-0.0293],\n",
      "        [ 0.0313],\n",
      "        [-0.0097],\n",
      "        [-0.0074]], grad_fn=<AddmmBackward>)\n",
      "151\n",
      "tensor([[-0.0924],\n",
      "        [-0.0399],\n",
      "        [ 0.0091],\n",
      "        [-0.1404]], grad_fn=<AddmmBackward>)\n",
      "152\n",
      "tensor([[-0.0894],\n",
      "        [-0.0436],\n",
      "        [-0.0466],\n",
      "        [-0.0448]], grad_fn=<AddmmBackward>)\n",
      "153\n",
      "tensor([[-0.0276],\n",
      "        [-0.0026],\n",
      "        [-0.0679],\n",
      "        [-0.0947]], grad_fn=<AddmmBackward>)\n",
      "154\n",
      "tensor([[-0.1483],\n",
      "        [-0.1008],\n",
      "        [ 0.0977],\n",
      "        [ 0.0379]], grad_fn=<AddmmBackward>)\n",
      "155\n",
      "tensor([[-0.1929],\n",
      "        [-0.0256],\n",
      "        [-0.0568],\n",
      "        [-0.0325]], grad_fn=<AddmmBackward>)\n",
      "156\n",
      "tensor([[-0.0419],\n",
      "        [-0.1219],\n",
      "        [-0.1440],\n",
      "        [-0.0929]], grad_fn=<AddmmBackward>)\n",
      "157\n",
      "tensor([[-0.0181],\n",
      "        [-0.0447],\n",
      "        [-0.0200],\n",
      "        [-0.0064]], grad_fn=<AddmmBackward>)\n",
      "158\n",
      "tensor([[-0.1442],\n",
      "        [-0.0639],\n",
      "        [-0.0867],\n",
      "        [-0.0235]], grad_fn=<AddmmBackward>)\n",
      "159\n",
      "tensor([[-0.1337],\n",
      "        [-0.1962],\n",
      "        [-0.1651],\n",
      "        [-0.1334]], grad_fn=<AddmmBackward>)\n",
      "160\n",
      "tensor([[-0.0368],\n",
      "        [-0.1179],\n",
      "        [-0.0337],\n",
      "        [-0.0523]], grad_fn=<AddmmBackward>)\n",
      "161\n",
      "tensor([[-0.0163],\n",
      "        [-0.0034],\n",
      "        [-0.0408],\n",
      "        [-0.0165]], grad_fn=<AddmmBackward>)\n",
      "162\n",
      "tensor([[-0.1372],\n",
      "        [-0.0212],\n",
      "        [-0.0184],\n",
      "        [-0.1953]], grad_fn=<AddmmBackward>)\n",
      "163\n",
      "tensor([[-0.0664],\n",
      "        [-0.0480],\n",
      "        [-0.0504],\n",
      "        [-0.1160]], grad_fn=<AddmmBackward>)\n",
      "164\n",
      "tensor([[-0.0890],\n",
      "        [-0.1048],\n",
      "        [-0.0057],\n",
      "        [-0.0355]], grad_fn=<AddmmBackward>)\n",
      "165\n",
      "tensor([[-0.0470],\n",
      "        [-0.0908],\n",
      "        [ 0.0029],\n",
      "        [-0.0387]], grad_fn=<AddmmBackward>)\n",
      "166\n",
      "tensor([[-0.0388],\n",
      "        [-0.0485],\n",
      "        [-0.1698],\n",
      "        [-0.0650]], grad_fn=<AddmmBackward>)\n",
      "167\n",
      "tensor([[-0.0989],\n",
      "        [-0.0651],\n",
      "        [-0.0387],\n",
      "        [-0.1364]], grad_fn=<AddmmBackward>)\n",
      "168\n",
      "tensor([[-0.0359],\n",
      "        [-0.1460],\n",
      "        [-0.1493],\n",
      "        [-0.1186]], grad_fn=<AddmmBackward>)\n",
      "169\n",
      "tensor([[-0.0631],\n",
      "        [-0.1170],\n",
      "        [-0.0722],\n",
      "        [-0.1524]], grad_fn=<AddmmBackward>)\n",
      "170\n",
      "tensor([[-0.1113],\n",
      "        [-0.1134],\n",
      "        [-0.1224],\n",
      "        [-0.0605]], grad_fn=<AddmmBackward>)\n",
      "171\n",
      "tensor([[-0.1263],\n",
      "        [-0.0976],\n",
      "        [-0.1032],\n",
      "        [-0.1016]], grad_fn=<AddmmBackward>)\n",
      "172\n",
      "tensor([[-0.1610],\n",
      "        [-0.1862],\n",
      "        [-0.1001],\n",
      "        [-0.0425]], grad_fn=<AddmmBackward>)\n",
      "173\n",
      "tensor([[-0.0401],\n",
      "        [-0.0855],\n",
      "        [ 0.0103],\n",
      "        [-0.1243]], grad_fn=<AddmmBackward>)\n",
      "174\n",
      "tensor([[-0.1365],\n",
      "        [-0.1218],\n",
      "        [-0.0540],\n",
      "        [-0.1095]], grad_fn=<AddmmBackward>)\n",
      "175\n",
      "tensor([[-0.1570],\n",
      "        [-0.0928],\n",
      "        [-0.1646],\n",
      "        [-0.0702]], grad_fn=<AddmmBackward>)\n",
      "176\n",
      "tensor([[-0.0952],\n",
      "        [-0.0833],\n",
      "        [-0.1271],\n",
      "        [-0.0354]], grad_fn=<AddmmBackward>)\n",
      "177\n",
      "tensor([[-0.0954],\n",
      "        [-0.1069],\n",
      "        [-0.0612],\n",
      "        [-0.0161]], grad_fn=<AddmmBackward>)\n",
      "178\n",
      "tensor([[-0.0422],\n",
      "        [-0.0798],\n",
      "        [-0.0734],\n",
      "        [-0.1182]], grad_fn=<AddmmBackward>)\n",
      "179\n",
      "tensor([[-0.0851],\n",
      "        [-0.1185],\n",
      "        [-0.1342],\n",
      "        [-0.0604]], grad_fn=<AddmmBackward>)\n",
      "180\n",
      "tensor([[-0.1162],\n",
      "        [-0.0386],\n",
      "        [-0.0859],\n",
      "        [-0.1820]], grad_fn=<AddmmBackward>)\n",
      "181\n",
      "tensor([[-0.1034],\n",
      "        [-0.1461],\n",
      "        [-0.1280],\n",
      "        [-0.1831]], grad_fn=<AddmmBackward>)\n",
      "182\n",
      "tensor([[-0.0549],\n",
      "        [-0.0816],\n",
      "        [-0.1046],\n",
      "        [-0.1782]], grad_fn=<AddmmBackward>)\n",
      "183\n",
      "tensor([[-0.0811],\n",
      "        [-0.1172],\n",
      "        [-0.1138],\n",
      "        [-0.1105]], grad_fn=<AddmmBackward>)\n",
      "184\n",
      "tensor([[-0.1220],\n",
      "        [-0.0587],\n",
      "        [-0.1539],\n",
      "        [-0.1064]], grad_fn=<AddmmBackward>)\n",
      "185\n",
      "tensor([[-0.1963],\n",
      "        [-0.2123],\n",
      "        [-0.1118],\n",
      "        [-0.0577]], grad_fn=<AddmmBackward>)\n",
      "186\n",
      "tensor([[-0.0721],\n",
      "        [-0.2000],\n",
      "        [-0.0998],\n",
      "        [-0.1459]], grad_fn=<AddmmBackward>)\n",
      "187\n",
      "tensor([[-0.1145],\n",
      "        [-0.0732],\n",
      "        [-0.1301],\n",
      "        [-0.0474]], grad_fn=<AddmmBackward>)\n",
      "188\n",
      "tensor([[-0.0477],\n",
      "        [-0.1525],\n",
      "        [-0.1562],\n",
      "        [-0.0495]], grad_fn=<AddmmBackward>)\n",
      "189\n",
      "tensor([[-0.1965],\n",
      "        [-0.1296],\n",
      "        [-0.0832],\n",
      "        [-0.0745]], grad_fn=<AddmmBackward>)\n",
      "190\n",
      "tensor([[-0.1065],\n",
      "        [-0.0851],\n",
      "        [-0.0847],\n",
      "        [-0.1390]], grad_fn=<AddmmBackward>)\n",
      "191\n",
      "tensor([[-0.1557],\n",
      "        [-0.0892],\n",
      "        [-0.1016],\n",
      "        [-0.0913]], grad_fn=<AddmmBackward>)\n",
      "192\n",
      "tensor([[-0.1162],\n",
      "        [-0.1308],\n",
      "        [-0.0891],\n",
      "        [-0.1309]], grad_fn=<AddmmBackward>)\n",
      "193\n",
      "tensor([[-0.0994],\n",
      "        [-0.1273],\n",
      "        [-0.0834],\n",
      "        [-0.0843]], grad_fn=<AddmmBackward>)\n",
      "194\n",
      "tensor([[-0.1316],\n",
      "        [-0.1507],\n",
      "        [-0.1204],\n",
      "        [-0.1617]], grad_fn=<AddmmBackward>)\n",
      "195\n",
      "tensor([[-0.1157],\n",
      "        [-0.0684],\n",
      "        [-0.0472],\n",
      "        [-0.0700]], grad_fn=<AddmmBackward>)\n",
      "196\n",
      "tensor([[-0.1991],\n",
      "        [-0.0749],\n",
      "        [-0.1517],\n",
      "        [-0.1348]], grad_fn=<AddmmBackward>)\n",
      "197\n",
      "tensor([[-0.0911],\n",
      "        [-0.2179],\n",
      "        [-0.1297],\n",
      "        [-0.1617]], grad_fn=<AddmmBackward>)\n",
      "198\n",
      "tensor([[-0.0369],\n",
      "        [-0.0912],\n",
      "        [-0.1428],\n",
      "        [-0.1864]], grad_fn=<AddmmBackward>)\n",
      "199\n",
      "tensor([[-0.1571],\n",
      "        [-0.0747],\n",
      "        [-0.1463],\n",
      "        [-0.1054]], grad_fn=<AddmmBackward>)\n",
      "200\n",
      "tensor([[-0.1093],\n",
      "        [-0.0508],\n",
      "        [-0.0628],\n",
      "        [-0.1311]], grad_fn=<AddmmBackward>)\n",
      "201\n",
      "tensor([[-0.0424],\n",
      "        [-0.1112],\n",
      "        [-0.1182],\n",
      "        [-0.1118]], grad_fn=<AddmmBackward>)\n",
      "202\n",
      "tensor([[-0.0735],\n",
      "        [-0.1773],\n",
      "        [-0.1508],\n",
      "        [-0.0816]], grad_fn=<AddmmBackward>)\n",
      "203\n",
      "tensor([[-0.1353],\n",
      "        [-0.1201],\n",
      "        [-0.1001],\n",
      "        [-0.0967]], grad_fn=<AddmmBackward>)\n",
      "204\n",
      "tensor([[-0.0912],\n",
      "        [-0.1504],\n",
      "        [-0.0801],\n",
      "        [-0.1687]], grad_fn=<AddmmBackward>)\n",
      "205\n",
      "tensor([[-0.0346],\n",
      "        [-0.1910],\n",
      "        [-0.1525],\n",
      "        [-0.0772]], grad_fn=<AddmmBackward>)\n",
      "206\n",
      "tensor([[-0.1303],\n",
      "        [-0.1079],\n",
      "        [-0.1657],\n",
      "        [-0.1511]], grad_fn=<AddmmBackward>)\n",
      "207\n",
      "tensor([[-0.1190],\n",
      "        [-0.2058],\n",
      "        [-0.1877],\n",
      "        [-0.1308]], grad_fn=<AddmmBackward>)\n",
      "208\n",
      "tensor([[-0.1540],\n",
      "        [-0.1396],\n",
      "        [-0.1284],\n",
      "        [-0.1673]], grad_fn=<AddmmBackward>)\n",
      "209\n",
      "tensor([[-0.1684],\n",
      "        [-0.1068],\n",
      "        [-0.0996],\n",
      "        [-0.0839]], grad_fn=<AddmmBackward>)\n",
      "210\n",
      "tensor([[-0.1594],\n",
      "        [-0.1180],\n",
      "        [-0.1463],\n",
      "        [-0.1458]], grad_fn=<AddmmBackward>)\n",
      "211\n",
      "tensor([[-0.0612],\n",
      "        [-0.1366],\n",
      "        [-0.1191],\n",
      "        [-0.1799]], grad_fn=<AddmmBackward>)\n",
      "212\n",
      "tensor([[-0.1085],\n",
      "        [-0.1189],\n",
      "        [-0.1484],\n",
      "        [-0.1654]], grad_fn=<AddmmBackward>)\n",
      "213\n",
      "tensor([[-0.1233],\n",
      "        [-0.1190],\n",
      "        [-0.1431],\n",
      "        [-0.1060]], grad_fn=<AddmmBackward>)\n",
      "214\n",
      "tensor([[-0.0802],\n",
      "        [-0.1073],\n",
      "        [-0.1484],\n",
      "        [-0.1253]], grad_fn=<AddmmBackward>)\n",
      "215\n",
      "tensor([[-0.1642],\n",
      "        [-0.1101],\n",
      "        [-0.1048],\n",
      "        [-0.1581]], grad_fn=<AddmmBackward>)\n",
      "216\n",
      "tensor([[-0.1651],\n",
      "        [-0.1213],\n",
      "        [-0.1320],\n",
      "        [-0.1610]], grad_fn=<AddmmBackward>)\n",
      "217\n",
      "tensor([[-0.1407],\n",
      "        [-0.1323],\n",
      "        [-0.1156],\n",
      "        [-0.1053]], grad_fn=<AddmmBackward>)\n",
      "218\n",
      "tensor([[-0.1720],\n",
      "        [-0.1648],\n",
      "        [-0.0885],\n",
      "        [-0.1008]], grad_fn=<AddmmBackward>)\n",
      "219\n",
      "tensor([[-0.0679],\n",
      "        [-0.0849],\n",
      "        [-0.0589],\n",
      "        [-0.0999]], grad_fn=<AddmmBackward>)\n",
      "220\n",
      "tensor([[-0.1379],\n",
      "        [-0.1027],\n",
      "        [-0.1310],\n",
      "        [-0.0906]], grad_fn=<AddmmBackward>)\n",
      "221\n",
      "tensor([[-0.1338],\n",
      "        [-0.1536],\n",
      "        [-0.0775],\n",
      "        [-0.1306]], grad_fn=<AddmmBackward>)\n",
      "222\n",
      "tensor([[-0.1617],\n",
      "        [-0.1180],\n",
      "        [-0.1450],\n",
      "        [-0.1527]], grad_fn=<AddmmBackward>)\n",
      "223\n",
      "tensor([[-0.1696],\n",
      "        [-0.1572],\n",
      "        [-0.0776],\n",
      "        [-0.1402]], grad_fn=<AddmmBackward>)\n",
      "224\n",
      "tensor([[-0.1163],\n",
      "        [-0.1372],\n",
      "        [-0.0938],\n",
      "        [-0.1403]], grad_fn=<AddmmBackward>)\n",
      "225\n",
      "tensor([[-0.1208],\n",
      "        [-0.1189],\n",
      "        [-0.1427],\n",
      "        [-0.1433]], grad_fn=<AddmmBackward>)\n",
      "226\n",
      "tensor([[-0.1178],\n",
      "        [-0.1784],\n",
      "        [-0.1721],\n",
      "        [-0.1589]], grad_fn=<AddmmBackward>)\n",
      "227\n",
      "tensor([[-0.0898],\n",
      "        [-0.1421],\n",
      "        [-0.1332],\n",
      "        [-0.1103]], grad_fn=<AddmmBackward>)\n",
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/cloud/Git/learning/ai-implementations/gan.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=5'>6</a>\u001b[0m g_optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=6'>7</a>\u001b[0m d_optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=8'>9</a>\u001b[0m dis_out_real \u001b[39m=\u001b[39m discriminator(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=10'>11</a>\u001b[0m noise \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(BATCH, \u001b[39m1\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m20\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=12'>13</a>\u001b[0m generated \u001b[39m=\u001b[39m generator(noise)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/cloud/Git/learning/ai-implementations/gan.ipynb Cell 7'\u001b[0m in \u001b[0;36mD.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=21'>22</a>\u001b[0m \tx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=23'>24</a>\u001b[0m \tx \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cloud/Git/learning/ai-implementations/gan.ipynb#ch0000011?line=25'>26</a>\u001b[0m \tx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py:439\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=434'>435</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=435'>436</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=436'>437</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(EPOCHS):\n",
    "\tfor i, data in enumerate(trainloader):\n",
    "\t\tprint(i)\n",
    "\t\timages = data[0]\n",
    "\n",
    "\t\tg_optim.zero_grad()\n",
    "\t\td_optim.zero_grad()\n",
    "\n",
    "\t\tdis_out_real = discriminator(images)\n",
    "\t\terror_real = loss_fn(dis_out_real, torch.ones(BATCH, 1))\n",
    "\t\terror_real.backward()\n",
    "\n",
    "\t\tnoise = torch.randn(BATCH, 1, 20, 20)\n",
    "\t\t\n",
    "\t\tgenerated = generator(noise)\n",
    "\n",
    "\t\tdis_out_fake = discriminator(generated)\n",
    "\t\terror_fake = loss_fn(dis_out_fake, torch.zeros(BATCH, 1))\n",
    "\t\terror_fake.backward()\n",
    "\n",
    "\t\tdis_loss = (error_real.item() + error_fake.item()) / 2\n",
    "\n",
    "\t\tg_optim.step()\n",
    "\n",
    "\t\t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
