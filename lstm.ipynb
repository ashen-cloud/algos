{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfuZoVzGX5O2eHDZsvdQjf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHn6K0u3-2lF",
        "outputId": "8aecd1d4-f9bf-4e19-dd38-83cb69e79dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import zipfile\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, GloVe, vocab\n",
        "\n",
        "\n",
        "from functools import partial,reduce\n",
        "from tqdm import tqdm, trange\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "trange = partial(trange, position=0, leave=True)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DEVICE = 'cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip'\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "ul = url.split('/')\n",
        "name = ul[len(ul) - 1]\n",
        "\n",
        "with open(name, 'wb') as file:\n",
        "  file.write(r.content)\n",
        "\n",
        "with zipfile.ZipFile(name, \"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"./\")\n",
        "\n",
        "!mv 'cornell movie-dialogs corpus' 'data'\n",
        "!ls 'data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN_cyVT6eQQM",
        "outputId": "2d16f6ec-28f1-4598-b0f6-badf94c6b7ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " chameleons.pdf\t\t\t movie_lines.txt\n",
            "'cornell movie-dialogs corpus'\t movie_titles_metadata.txt\n",
            " movie_characters_metadata.txt\t raw_script_urls.txt\n",
            " movie_conversations.txt\t README.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V_jfwwVQKw-o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FIELD_SPLITTER = '+++$+++'\n",
        "\n",
        "MAX_SAMPLES = 50000\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "UNK_TOKEN = '<unk>'\n",
        "PAD_TOKEN = '<PAD>'\n",
        "BOS_TOKEN = '<BOS>'\n",
        "EOS_TOKEN = '<EOS>'\n",
        "\n",
        "UNK_TOKEN_IND = 0\n",
        "PAD_TOKEN_IND = 1\n",
        "BOS_TOKEN_IND = 2\n",
        "EOS_TOKEN_IND = 3\n",
        "\n",
        "BATCH = 2"
      ],
      "metadata": {
        "id": "Kx8U5FhayR-T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PW9kkcKGvkht"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "-FmVEHllv777"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x, voc, tokenizer: [voc['<BOS>']] + [voc[token] for token in tokenizer(x)] + [voc['<EOS>']]"
      ],
      "metadata": {
        "id": "5xjiwfyZwZbt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is terrible as fuck because torchtext is terrible as fuck\n",
        "def load_conversations(path_to_movie_lines, path_to_movie_conversations):\n",
        "    id2line = {}\n",
        "    with open(path_to_movie_lines, errors='ignore') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "            id2line[parts[0]] = parts[4]\n",
        "\n",
        "    inputs, outputs = [], []\n",
        "    with open(path_to_movie_conversations, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "            conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "            for i in range(len(conversation) - 1):\n",
        "                inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "                outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "                if len(inputs) >= MAX_SAMPLES:\n",
        "                    return inputs, outputs\n",
        "    return inputs, outputs\n"
      ],
      "metadata": {
        "id": "-sijVHLArNQJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(path_to_movie_lines,\n",
        "                   path_to_movie_conversations):\n",
        "    questions, answers = load_conversations(path_to_movie_lines, path_to_movie_conversations)\n",
        "\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    counter = Counter()\n",
        "    for sent in questions + answers:\n",
        "        counter.update(tokenizer(sent))\n",
        "\n",
        "    voc = vocab(counter)\n",
        "    voc.insert_token(token=UNK_TOKEN, index=UNK_TOKEN_IND)\n",
        "    voc.set_default_index(index=UNK_TOKEN_IND)\n",
        "    voc.insert_token(token=PAD_TOKEN, index=PAD_TOKEN_IND)\n",
        "    voc.insert_token(token=BOS_TOKEN, index=BOS_TOKEN_IND)\n",
        "    voc.insert_token(token=EOS_TOKEN, index=EOS_TOKEN_IND)\n",
        "\n",
        "    q_tokenized = [text_transform(t, voc, tokenizer) for t in questions]\n",
        "    a_tokenized = [text_transform(t, voc, tokenizer) for t in answers]\n",
        "\n",
        "    import tensorflow as tf # todo\n",
        "    q_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        q_tokenized, maxlen=MAX_LENGTH, padding='post', value=1.0)\n",
        "\n",
        "    a_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        a_tokenized, maxlen=MAX_LENGTH, padding='post', value=1.0)\n",
        "\n",
        "    print(\"Vocab len\", len(voc))\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        list(\n",
        "            zip(\n",
        "                  q_padded.astype(np.float32),\n",
        "                  a_padded.astype(np.float32),\n",
        "                )\n",
        "            ),\n",
        "            batch_size=BATCH,\n",
        "            shuffle=False,\n",
        "    )\n",
        "\n",
        "    print(voc)\n",
        "    torch.save(voc, 'vocab')\n",
        "\n",
        "    return dataloader, text_transform, voc\n"
      ],
      "metadata": {
        "id": "dblp_TVLqvav"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3T8xN1yxmyc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_path = 'data/movie_lines.txt'\n",
        "conversations_path = 'data/movie_conversations.txt'    \n",
        "\n",
        "dataloader, text_transform, voc = get_dataloader(lines_path,\n",
        "                                                 conversations_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e42tdLcayovn",
        "outputId": "3683b520-37b4-4a8f-8c6f-4feaa59ebf27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab len 23068\n",
            "Vocab()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = None\n",
        "\n",
        "for i,x in enumerate(dataloader):\n",
        "  if i > 1: break\n",
        "  print(x[0].shape)\n",
        "  test_sample = x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMyWFI7N3VVf",
        "outputId": "a2fa472d-902f-4c26-d102-d61360661c78"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 40])\n",
            "torch.Size([2, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OG_PUCipfDAT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.oreilly.com%2Flibrary%2Fview%2Fneural-networks-and%2F9781492037354%2Fassets%2Fmlst_1413.png&f=1&nofb=1\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, isize, osize):\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    self.isize = isize\n",
        "    self.osize = osize\n",
        "\n",
        "    self.f = nn.Linear(isize, osize)\n",
        "    self.g = nn.Linear(isize, osize)\n",
        "    self.i = nn.Linear(isize, osize)\n",
        "    self.o = nn.Linear(isize, osize)\n",
        "\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forget_gate(self, h, x, c):\n",
        "    fho = self.f(h)\n",
        "    fxo = self.f(x)\n",
        "\n",
        "    fo = fho + fxo\n",
        "    fos = self.sigmoid(fo)\n",
        "    out = torch.mul(c, fos)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def input_gate(self, h, x):\n",
        "    gho = self.g(h)\n",
        "    gxo = self.g(x)\n",
        "    go = gho + gxo\n",
        "    gto = self.tanh(go)\n",
        "\n",
        "    iho = self.i(h)\n",
        "    ixo = self.i(x)\n",
        "    io = iho + ixo\n",
        "    ito = self.sigmoid(io)\n",
        "\n",
        "    print(gto.shape, ito.shape)\n",
        "    out = torch.mul(gto, ito)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def output_gate(self, h, x, cn):\n",
        "    oho = self.o(h)\n",
        "    oxo = self.o(x)\n",
        "    oo = oho + oxo\n",
        "\n",
        "    out = torch.mul(oo, cn)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def forward(self, x, h0=None, c0=None):\n",
        "    if not h0:\n",
        "      h0 = torch.zeros(x.shape[0], self.isize)\n",
        "    if not c0:\n",
        "      c0 = torch.zeros(x.shape[0], self.osize)\n",
        "\n",
        "    fg_out = self.forget_gate(h0, x, c0)\n",
        "    ig_out = self.input_gate(h0, x)\n",
        "\n",
        "    c_new = fg_out + ig_out\n",
        "\n",
        "    cnt = self.tanh(c_new) \n",
        "\n",
        "    h_new = self.output_gate(h0, x, c_new)\n",
        "\n",
        "    out = h_new\n",
        "\n",
        "    return out, (h_new, c_new)\n"
      ],
      "metadata": {
        "id": "Iajk3iU8hKlB"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_lstm = LSTM(40, 80)\n",
        "\n",
        "out, (h, c) = my_lstm(test_sample)\n",
        "\n",
        "print(out.shape)\n",
        "print(out)\n",
        "print('\\n----------------')\n",
        "print(h.shape)\n",
        "print(h)\n",
        "print('\\n----------------')\n",
        "print(c.shape)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic6e2QJcHlqj",
        "outputId": "f1d23458-e5da-4ea2-8ab2-95cca73944b8"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 80]) torch.Size([2, 80])\n",
            "torch.Size([2, 80])\n",
            "tensor([[-1.4674e-03, -5.0430e+00,  9.3533e+00,  1.9533e+00,  1.1137e+00,\n",
            "         -2.3917e-06,  7.2047e+00, -3.4163e-01,  3.8996e+00, -1.6308e-03,\n",
            "          9.2821e+00, -1.0249e+01, -2.0752e+01, -8.0536e-03, -1.6357e+01,\n",
            "         -8.8634e+00, -1.1861e+01,  4.9321e+00, -6.6905e+00, -9.5990e+00,\n",
            "          5.8808e+00,  1.0157e-06, -5.1388e+00,  2.2135e+00,  3.7224e-02,\n",
            "         -5.2040e-05, -3.8808e+00,  7.4679e-05,  3.3302e+00, -2.6798e-07,\n",
            "         -4.3820e-02,  9.9563e+00, -1.2414e+00,  2.7979e-01,  2.7267e+00,\n",
            "          3.3662e+00,  4.5779e+00,  1.6907e+00,  2.1736e-03, -1.5878e-01,\n",
            "          1.8046e-06,  9.1593e-02, -1.3679e+00,  4.4969e+00,  1.5936e-08,\n",
            "         -8.8859e-08,  1.1087e+01,  1.4038e+01, -2.1818e+01,  4.9290e+00,\n",
            "          9.8502e+00, -2.4420e-08, -1.7005e-10,  9.6493e+00,  8.2473e-01,\n",
            "         -1.4403e-01, -1.0829e-06, -3.9287e-04, -2.1566e+01, -4.4556e+00,\n",
            "         -1.6597e+01, -3.5435e+00,  5.0527e-05, -2.2282e-04, -1.0753e+01,\n",
            "         -5.6837e+00,  4.3004e-03,  9.8245e-04, -2.2470e-04,  8.1997e-01,\n",
            "          2.5304e-07, -7.8340e-07,  2.1084e-01, -1.7084e+00, -1.6566e+01,\n",
            "         -3.1019e+00, -9.5219e+00, -2.5263e+00,  1.5674e+01,  8.7411e-01],\n",
            "        [ 2.8927e-05, -6.9173e+00, -7.5565e-01,  1.6441e+01,  1.2792e+01,\n",
            "          1.2660e-09, -8.1317e-02,  7.3331e-02, -1.5705e+00, -5.5488e-07,\n",
            "         -9.7915e+00, -3.4864e-02, -2.3659e+00,  2.1421e+01,  2.0182e+00,\n",
            "          3.0741e+01, -2.3735e+01,  1.9190e+00,  7.8586e+00,  5.3884e+00,\n",
            "         -1.1562e+01,  3.1532e-02,  3.9530e+00, -1.0551e+01, -4.9107e-06,\n",
            "         -7.1873e-03,  6.6618e-02,  1.4831e-05, -3.9130e+00,  2.6136e-06,\n",
            "          2.2401e+01,  1.5230e+01, -1.3667e+01,  1.0963e-03, -9.0544e-02,\n",
            "          1.2394e+01,  1.5274e+01, -2.5071e+00, -2.6560e+00, -3.3375e-04,\n",
            "          5.1496e-13, -1.2272e+01, -9.2579e+00, -1.7701e+00,  2.0129e-15,\n",
            "          7.5357e-09, -1.3536e-02,  3.1237e+01,  1.5728e+01,  8.7218e+00,\n",
            "         -1.0586e+01,  2.7169e-18, -5.6563e-13,  1.2634e+01,  2.2904e-07,\n",
            "         -1.9525e+01, -5.3192e-12, -6.9918e-06,  6.3145e-02, -2.4669e+00,\n",
            "         -1.7931e+01,  1.0071e+00,  1.2713e+01,  2.4152e-01, -6.8236e-07,\n",
            "         -1.1244e+00, -4.4398e-02,  9.4355e-07, -3.7404e-06,  1.5420e+01,\n",
            "          6.4078e-12,  2.6354e-02,  2.0324e+01,  1.4450e-02, -1.4483e+01,\n",
            "         -5.1364e-01, -8.9734e+00, -6.5482e+00,  1.9343e+01, -1.1098e+00]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "\n",
            "----------------\n",
            "torch.Size([2, 80])\n",
            "tensor([[-1.4674e-03, -5.0430e+00,  9.3533e+00,  1.9533e+00,  1.1137e+00,\n",
            "         -2.3917e-06,  7.2047e+00, -3.4163e-01,  3.8996e+00, -1.6308e-03,\n",
            "          9.2821e+00, -1.0249e+01, -2.0752e+01, -8.0536e-03, -1.6357e+01,\n",
            "         -8.8634e+00, -1.1861e+01,  4.9321e+00, -6.6905e+00, -9.5990e+00,\n",
            "          5.8808e+00,  1.0157e-06, -5.1388e+00,  2.2135e+00,  3.7224e-02,\n",
            "         -5.2040e-05, -3.8808e+00,  7.4679e-05,  3.3302e+00, -2.6798e-07,\n",
            "         -4.3820e-02,  9.9563e+00, -1.2414e+00,  2.7979e-01,  2.7267e+00,\n",
            "          3.3662e+00,  4.5779e+00,  1.6907e+00,  2.1736e-03, -1.5878e-01,\n",
            "          1.8046e-06,  9.1593e-02, -1.3679e+00,  4.4969e+00,  1.5936e-08,\n",
            "         -8.8859e-08,  1.1087e+01,  1.4038e+01, -2.1818e+01,  4.9290e+00,\n",
            "          9.8502e+00, -2.4420e-08, -1.7005e-10,  9.6493e+00,  8.2473e-01,\n",
            "         -1.4403e-01, -1.0829e-06, -3.9287e-04, -2.1566e+01, -4.4556e+00,\n",
            "         -1.6597e+01, -3.5435e+00,  5.0527e-05, -2.2282e-04, -1.0753e+01,\n",
            "         -5.6837e+00,  4.3004e-03,  9.8245e-04, -2.2470e-04,  8.1997e-01,\n",
            "          2.5304e-07, -7.8340e-07,  2.1084e-01, -1.7084e+00, -1.6566e+01,\n",
            "         -3.1019e+00, -9.5219e+00, -2.5263e+00,  1.5674e+01,  8.7411e-01],\n",
            "        [ 2.8927e-05, -6.9173e+00, -7.5565e-01,  1.6441e+01,  1.2792e+01,\n",
            "          1.2660e-09, -8.1317e-02,  7.3331e-02, -1.5705e+00, -5.5488e-07,\n",
            "         -9.7915e+00, -3.4864e-02, -2.3659e+00,  2.1421e+01,  2.0182e+00,\n",
            "          3.0741e+01, -2.3735e+01,  1.9190e+00,  7.8586e+00,  5.3884e+00,\n",
            "         -1.1562e+01,  3.1532e-02,  3.9530e+00, -1.0551e+01, -4.9107e-06,\n",
            "         -7.1873e-03,  6.6618e-02,  1.4831e-05, -3.9130e+00,  2.6136e-06,\n",
            "          2.2401e+01,  1.5230e+01, -1.3667e+01,  1.0963e-03, -9.0544e-02,\n",
            "          1.2394e+01,  1.5274e+01, -2.5071e+00, -2.6560e+00, -3.3375e-04,\n",
            "          5.1496e-13, -1.2272e+01, -9.2579e+00, -1.7701e+00,  2.0129e-15,\n",
            "          7.5357e-09, -1.3536e-02,  3.1237e+01,  1.5728e+01,  8.7218e+00,\n",
            "         -1.0586e+01,  2.7169e-18, -5.6563e-13,  1.2634e+01,  2.2904e-07,\n",
            "         -1.9525e+01, -5.3192e-12, -6.9918e-06,  6.3145e-02, -2.4669e+00,\n",
            "         -1.7931e+01,  1.0071e+00,  1.2713e+01,  2.4152e-01, -6.8236e-07,\n",
            "         -1.1244e+00, -4.4398e-02,  9.4355e-07, -3.7404e-06,  1.5420e+01,\n",
            "          6.4078e-12,  2.6354e-02,  2.0324e+01,  1.4450e-02, -1.4483e+01,\n",
            "         -5.1364e-01, -8.9734e+00, -6.5482e+00,  1.9343e+01, -1.1098e+00]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "\n",
            "----------------\n",
            "torch.Size([2, 80])\n",
            "tensor([[ 3.5055e-04, -9.9999e-01, -8.9185e-01,  9.9191e-01,  1.1112e-01,\n",
            "          1.1395e-05,  8.6044e-01,  3.9811e-02,  9.9718e-01,  1.0537e-04,\n",
            "          4.3567e-01,  9.9590e-01, -9.5039e-01,  2.3512e-01,  1.0000e+00,\n",
            "         -9.9150e-01, -9.9989e-01,  9.9986e-01, -9.9999e-01,  1.0000e+00,\n",
            "          9.9948e-01, -1.3708e-07,  9.7519e-01,  2.8938e-01,  5.7233e-03,\n",
            "         -2.6049e-05,  9.4672e-01,  1.1985e-05,  9.2070e-01, -2.0710e-07,\n",
            "         -3.9448e-02,  7.1248e-01, -1.5923e-01,  9.6767e-01, -1.0000e+00,\n",
            "         -2.1518e-01,  9.9082e-01, -1.0000e+00,  2.1690e-04, -1.2710e-02,\n",
            "          1.0616e-07, -4.2117e-03, -9.9151e-01,  9.9999e-01, -2.4718e-09,\n",
            "         -8.9840e-09,  9.4834e-01, -9.9961e-01, -9.9998e-01,  1.0000e+00,\n",
            "          9.8878e-01, -3.7577e-09,  9.4204e-11, -9.9341e-01, -3.5354e-01,\n",
            "          3.5127e-01, -8.5912e-08, -1.3834e-04, -9.9990e-01,  9.9793e-01,\n",
            "         -1.0000e+00, -9.7402e-01,  6.2183e-06,  2.2184e-05, -9.9642e-01,\n",
            "         -9.9999e-01,  1.5887e-03, -1.6741e-04,  3.1303e-05,  9.4136e-01,\n",
            "          2.5203e-07,  9.3546e-08,  6.3002e-02,  9.5961e-01,  9.9965e-01,\n",
            "          9.8194e-01,  6.9915e-01,  9.9993e-01, -9.8974e-01, -1.1593e-01],\n",
            "        [ 3.1854e-06, -1.0000e+00, -4.8930e-02,  9.9998e-01,  6.4303e-01,\n",
            "          9.8963e-11, -4.4772e-03, -2.8914e-03,  1.0000e+00,  4.6001e-08,\n",
            "         -1.0000e+00,  1.5264e-03, -7.6051e-02,  9.9546e-01, -6.7627e-02,\n",
            "          1.0000e+00, -1.0000e+00,  3.3754e-01, -1.0000e+00, -1.7579e-01,\n",
            "         -9.9135e-01, -3.1066e-02,  9.9959e-01,  1.0000e+00,  3.7977e-06,\n",
            "         -3.9886e-04,  1.9983e-02,  2.2120e-06, -6.8407e-01, -3.2018e-07,\n",
            "          9.4542e-01,  1.0000e+00, -9.8035e-01,  4.8504e-05,  2.6339e-02,\n",
            "         -9.9995e-01,  9.9996e-01,  1.0000e+00, -7.7639e-01, -2.4849e-05,\n",
            "          2.1076e-14,  8.0659e-01, -1.0000e+00,  9.9997e-01, -2.2371e-16,\n",
            "          4.0263e-10, -4.9525e-04, -9.9147e-01,  9.2081e-01,  9.6808e-01,\n",
            "         -9.2282e-01,  2.3837e-19,  2.2742e-14, -9.9052e-01, -1.3926e-08,\n",
            "          9.6105e-01, -7.2974e-13,  6.4173e-07,  6.3558e-03,  2.5075e-01,\n",
            "         -9.9834e-01,  1.2959e-01, -9.3440e-01, -1.7704e-02, -5.3621e-08,\n",
            "         -9.9994e-01,  7.4471e-03,  3.4863e-07,  1.8339e-07, -9.9990e-01,\n",
            "          1.8865e-13, -3.2725e-02,  9.8657e-01, -1.5191e-03,  9.9999e-01,\n",
            "          2.7998e-02,  1.0000e+00,  1.0000e+00, -9.9744e-01, -9.9497e-01]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YImpb8ymHlsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xcvxNbhgfh3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_sample.shape)\n",
        "print(test_sample.dtype "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_FMbHcG3-e-",
        "outputId": "df654e07-f163-4b10-90a2-7c5bd92361aa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 40])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_lstm = nn.LSTM(40, 80, batch_first=True)\n",
        "\n",
        "res, (h_s, c_s) = t_lstm(test_sample)\n",
        "\n",
        "print(res.shape)\n",
        "print(res)\n",
        "print('\\n---------')\n",
        "print(h_s.shape)\n",
        "print(h_s)\n",
        "print('\\n---------')\n",
        "print(c_s.shape)\n",
        "print(c_s)\n",
        "print('\\n---------')"
      ],
      "metadata": {
        "id": "QfkMe8hL0oi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c1d451e-4c63-4265-befd-015004979ddc"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 80])\n",
            "tensor([[-3.5065e-03, -1.9093e-05,  9.2510e-06,  9.8781e-05, -5.7811e-01,\n",
            "         -3.2824e-08,  3.6725e-02, -7.2311e-01,  1.0724e-02, -3.1983e-01,\n",
            "         -2.3204e-01,  2.7326e-01, -1.1981e-01,  6.8479e-01,  8.7582e-03,\n",
            "          1.4554e-04,  2.0267e-04, -6.2998e-06,  5.9079e-04, -3.0727e-01,\n",
            "          3.1095e-03, -1.9977e-05,  3.3266e-05,  7.1113e-04, -4.0071e-03,\n",
            "         -3.6446e-12,  5.4377e-01, -7.6159e-01, -7.5062e-04, -6.0906e-04,\n",
            "          7.8045e-08,  1.3249e-01,  7.6098e-01,  3.9227e-02,  6.1729e-01,\n",
            "          2.1250e-05,  3.3744e-01, -5.7826e-06,  3.1647e-04, -4.3004e-13,\n",
            "         -3.7966e-05, -3.4999e-01, -1.0875e-01, -6.4876e-04, -6.6209e-01,\n",
            "          1.4063e-01, -3.2276e-05, -2.8892e-09, -7.2229e-08, -1.4007e-01,\n",
            "          1.4035e-02, -6.8325e-03, -8.6691e-03, -4.0947e-05, -7.5320e-01,\n",
            "          1.3997e-03, -7.4605e-01, -6.9942e-01,  7.5422e-01,  7.2532e-01,\n",
            "          6.0891e-01, -2.8445e-01, -6.8476e-01,  9.3698e-05,  1.1946e-04,\n",
            "         -5.8461e-01, -4.3203e-03, -1.2837e-01,  6.2722e-01,  1.6095e-02,\n",
            "          2.0862e-05,  4.7239e-01, -1.9337e-04, -1.1385e-01, -8.9188e-03,\n",
            "         -1.4492e-02,  7.4762e-01,  1.8171e-10,  7.3439e-04, -7.1680e-01],\n",
            "        [-8.1841e-04, -2.9082e-04,  1.0199e-08, -2.6084e-03,  7.5185e-01,\n",
            "          3.2103e-07,  3.2832e-04, -6.6283e-01,  6.3680e-01, -2.7238e-01,\n",
            "          6.3950e-01, -4.6480e-01, -6.9548e-10,  6.6892e-01,  7.5396e-01,\n",
            "          8.3603e-06,  3.2125e-11, -6.1105e-06,  5.5563e-05, -6.0485e-02,\n",
            "          2.7456e-04, -1.6140e-05,  7.7005e-09,  8.2966e-06, -7.1026e-04,\n",
            "         -1.7020e-17,  4.7195e-01, -9.3272e-01, -2.5081e-01,  5.5645e-05,\n",
            "          8.4400e-07, -2.9692e-01,  9.3970e-01,  6.7633e-05,  6.2738e-01,\n",
            "          6.3346e-07,  7.6065e-01, -4.7222e-08, -2.6514e-03,  2.4326e-13,\n",
            "         -4.0614e-08, -5.2431e-01, -8.0273e-01,  7.9628e-07, -4.0011e-04,\n",
            "          1.3737e-01, -4.8704e-05, -6.2870e-07, -6.2619e-09, -3.2073e-02,\n",
            "          2.0810e-06, -1.7973e-05, -2.1223e-06, -2.9966e-11, -7.6169e-01,\n",
            "          2.8089e-01, -7.3949e-01, -1.4410e-01,  3.7901e-01,  9.6348e-01,\n",
            "          5.2473e-01, -2.8379e-01, -2.9496e-02, -8.7531e-08,  6.9685e-05,\n",
            "         -1.2885e-02, -1.1778e-06, -6.1855e-01,  6.2279e-01,  8.3418e-02,\n",
            "          5.7801e-12,  8.8886e-01,  8.0370e-03, -2.3385e-04, -3.6946e-03,\n",
            "         -2.2108e-07,  4.7270e-01,  1.0565e-12,  7.3441e-04, -9.3581e-01]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "\n",
            "---------\n",
            "torch.Size([1, 80])\n",
            "tensor([[-8.1841e-04, -2.9082e-04,  1.0199e-08, -2.6084e-03,  7.5185e-01,\n",
            "          3.2103e-07,  3.2832e-04, -6.6283e-01,  6.3680e-01, -2.7238e-01,\n",
            "          6.3950e-01, -4.6480e-01, -6.9548e-10,  6.6892e-01,  7.5396e-01,\n",
            "          8.3603e-06,  3.2125e-11, -6.1105e-06,  5.5563e-05, -6.0485e-02,\n",
            "          2.7456e-04, -1.6140e-05,  7.7005e-09,  8.2966e-06, -7.1026e-04,\n",
            "         -1.7020e-17,  4.7195e-01, -9.3272e-01, -2.5081e-01,  5.5645e-05,\n",
            "          8.4400e-07, -2.9692e-01,  9.3970e-01,  6.7633e-05,  6.2738e-01,\n",
            "          6.3346e-07,  7.6065e-01, -4.7222e-08, -2.6514e-03,  2.4326e-13,\n",
            "         -4.0614e-08, -5.2431e-01, -8.0273e-01,  7.9628e-07, -4.0011e-04,\n",
            "          1.3737e-01, -4.8704e-05, -6.2870e-07, -6.2619e-09, -3.2073e-02,\n",
            "          2.0810e-06, -1.7973e-05, -2.1223e-06, -2.9966e-11, -7.6169e-01,\n",
            "          2.8089e-01, -7.3949e-01, -1.4410e-01,  3.7901e-01,  9.6348e-01,\n",
            "          5.2473e-01, -2.8379e-01, -2.9496e-02, -8.7531e-08,  6.9685e-05,\n",
            "         -1.2885e-02, -1.1778e-06, -6.1855e-01,  6.2279e-01,  8.3418e-02,\n",
            "          5.7801e-12,  8.8886e-01,  8.0370e-03, -2.3385e-04, -3.6946e-03,\n",
            "         -2.2108e-07,  4.7270e-01,  1.0565e-12,  7.3441e-04, -9.3581e-01]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "\n",
            "---------\n",
            "torch.Size([1, 80])\n",
            "tensor([[-8.1841e-04, -6.8360e-04,  1.9811e+00, -8.6944e-01,  9.7809e-01,\n",
            "          3.8239e-01,  1.2893e+00, -8.2759e-01,  7.6693e-01, -2.8031e-01,\n",
            "          7.5734e-01, -9.3338e-01, -2.1137e-07,  8.0880e-01,  1.0081e+00,\n",
            "          1.0110e+00,  3.2125e-11, -6.1106e-06,  1.0010e+00, -1.3204e+00,\n",
            "          2.7456e-04, -4.1990e-02,  1.3410e+00,  8.2966e-06, -1.6303e+00,\n",
            "         -1.9810e-07,  5.1264e-01, -1.7407e+00, -2.5627e-01,  5.7357e-05,\n",
            "          9.1364e-05, -3.1166e-01,  1.7357e+00,  1.0000e+00,  1.6786e+00,\n",
            "          6.8155e-07,  9.9776e-01, -3.1560e-02, -1.1911e-02,  6.0744e-06,\n",
            "         -5.8755e-03, -5.8227e-01, -1.1098e+00,  6.9201e-01, -1.6402e+00,\n",
            "          1.4919e-01, -4.8704e-05, -2.9154e-06, -8.3662e-07, -1.0846e+00,\n",
            "          5.6517e-03, -9.9181e-01, -9.5845e-01, -3.6011e-11, -1.0002e+00,\n",
            "          1.9921e+00, -1.9999e+00, -8.8972e-01,  1.5834e+00,  1.9926e+00,\n",
            "          5.8314e-01, -2.9319e-01, -2.9504e-02, -9.4891e-01,  1.0717e+00,\n",
            "         -1.9998e+00, -2.6623e-03, -1.5364e+00,  7.3193e-01,  1.9116e+00,\n",
            "          1.7674e-10,  1.4166e+00,  2.1645e-01, -2.6180e-01, -3.6947e-03,\n",
            "         -1.0000e+00,  1.9816e+00,  1.3751e-05,  7.3441e-04, -1.8480e+00]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "\n",
            "---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Jxr4MUuSKxHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B_OfGA35gbyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wi7GRvfpevfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QtVP3qoOKxRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y4GSVA0xKxVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s1cpwVbSKxZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Up2jkK36zGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xrr5i0IpzGCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGWG3mbzzGEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mum903TXzGHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LfUhnHL_Kxcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ddwvBDsnKxf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data/movie_conversations.txt | tail -n 10"
      ],
      "metadata": {
        "id": "4kVqD08vKxjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "id": "zKWhBqLmKxoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data/README.txt"
      ],
      "metadata": {
        "id": "mm4in0NdubQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # trash\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def preprocess(x):\n",
        "#   x_no_new = x.replace('\\n', '')\n",
        "#   text = x_no_new.split(FIELD_SPLITTER).pop()\n",
        "#   embedding = g_vectors.get_vecs_by_tokens(tokenizer(text), lower_case_backup=True)\n",
        "#   return embedding\n",
        "\n",
        "# tokenizer = get_tokenizer('basic_english')\n",
        "# g_vectors = GloVe(name='840B')\n",
        "# g_vocab = vocab(g_vectors.stoi)\n",
        "\n",
        "\n",
        "# train_iter = tt.data.BucketIterator(\n",
        "#   dataset=train_obj,\n",
        "#   batch_size = 2,\n",
        "#   sort_key=lambda x: len(x.review),\n",
        "#   shuffle=True,\n",
        "#   device=DEVICE\n",
        "# )\n",
        "\n",
        "# trainloader = torch.utils.data.DataLoader(\n",
        "# \t,\n",
        "# \tbatch_size=BATCH,\n",
        "# \tnum_workers=12,\n",
        "# \tshuffle=True\n",
        "# )"
      ],
      "metadata": {
        "id": "UBDoHXDJsqu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# embeddings = global_vectors.get_vecs_by_tokens(tokenizer(\"Hello, How are you?\"),\n",
        "#                                                lower_case_backup=True)\n",
        "# embeddings\n",
        "# \n",
        "# \n",
        "# \n",
        "# def batch(iterable, size):\n",
        "#     from itertools import chain, islice\n",
        "#     iterator = iter(iterable)\n",
        "#     for first in iterator:\n",
        "#         yield list(chain([first], islice(iterator, size - 1)))"
      ],
      "metadata": {
        "id": "DRxfxpjQsrTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}